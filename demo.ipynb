{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9faf0b4e03d4e6f7209c7bf220319b218e0412f6e580604c4ee9d139a63e58e1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SSCDNonLModel99999999_(class_count,n_bands,150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSCDNonLModel(nn.Module):\n",
    "    def __init__(self, num_classes, n_bands, chanel):\n",
    "        super(SSCDNonLModel, self).__init__()\n",
    "        #self.num_Node=num_Node\n",
    "        self.bands=n_bands\n",
    "        chanel=chanel\n",
    "        kernel=5\n",
    "        CCChannel=25\n",
    "        # 第一层\n",
    "        self.b1=nn.BatchNorm2d(self.bands)\n",
    "        self.con1=nn.Conv2d(self.bands, chanel, 1, padding=0,bias=True)\n",
    "        self.s1=nn.Sigmoid()\n",
    "        self.cond1=nn.Conv2d(chanel, chanel, kernel, padding=2, groups=chanel, bias=True)\n",
    "        self.sd1=nn.Sigmoid()\n",
    "\n",
    "        # 第二层\n",
    "        self.b2=nn.BatchNorm2d(self.bands+chanel)\n",
    "        #self.nlcon1=NonLocalBlock(300, 300, True)\n",
    "        #self.gcn1=GCNtrans(300,1000)\n",
    "        #self.bcat=nn.BatchNorm2d(300+300)\n",
    "        self.con2=nn.Conv2d(self.bands+chanel, chanel, 1, padding=0,bias=True)\n",
    "        self.s2=nn.Sigmoid()\n",
    "        self.cond2=nn.Conv2d(chanel, CCChannel, kernel, padding=2, groups=25, bias=True)\n",
    "        self.sd2=nn.Sigmoid()\n",
    "        \n",
    "        #对齐维度\n",
    "        self.b4=nn.BatchNorm2d(CCChannel)\n",
    "        # 条状池化\n",
    "        self.nlcon2=CrissCrossAttention(CCChannel)\n",
    "        self.nlcon3=CrissCrossAttention(CCChannel)\n",
    "        #连接特征\n",
    "        self.bcat=nn.BatchNorm2d(CCChannel+CCChannel)\n",
    "        # 第三层\n",
    "        # 拼接第二层输出和cc输出\n",
    "        self.con4=nn.Conv2d(CCChannel+CCChannel, chanel, 1, padding=0, bias=True)\n",
    "        self.s4=nn.Sigmoid()\n",
    "        self.cond4=nn.Conv2d(chanel, chanel, kernel, padding=2, groups=chanel, bias=True)\n",
    "        self.sd4=nn.Sigmoid()\n",
    "        \n",
    "        第四层\n",
    "        self.b5=nn.BatchNorm2d(CCChannel+chanel)\n",
    "        self.con5=nn.Conv2d(CCChannel+chanel, chanel, 1, padding=0, bias=True)\n",
    "        self.s5=nn.Sigmoid()\n",
    "        self.cond5=nn.Conv2d(chanel, chanel, kernel, padding=2, groups=chanel, bias=True)\n",
    "        self.sd5=nn.Sigmoid()\n",
    "\n",
    "        #self.b6=nn.BatchNorm2d(300+300)\n",
    "        self.con6=nn.Conv2d(chanel+CCChannel, num_classes+1, 1, padding=0, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = x.size(0)\n",
    "        H=x.size(2)\n",
    "        W=x.size(3)\n",
    "\n",
    "        out1=self.b1(x)\n",
    "        out1=self.con1(out1)\n",
    "        out1=self.s1(out1)\n",
    "        out1=self.cond1(out1)\n",
    "        out1=self.sd1(out1)\n",
    "\n",
    "        # 拼接特征，对齐维度\n",
    "        out2=torch.cat((out1,x),1)\n",
    "        out2=self.b2(out2)\n",
    "        out2=self.con2(out2)\n",
    "        out2=self.s2(out2)\n",
    "        out2=self.cond2(out2)\n",
    "        out2=self.sd2(out2)\n",
    "\n",
    "        \n",
    "        xx=self.b4(out2)\n",
    "        #循环cc\n",
    "        nl2=self.nlcon2(xx)\n",
    "        nl2=self.nlcon2(nl2)\n",
    "        nl3=self.nlcon3(xx)\n",
    "        nl3=self.nlcon3(nl3)\n",
    "        #得到输出\n",
    "        nl2=(nl2+nl3)*0.7+xx\n",
    "        out4=torch.cat((xx, nl2),1)\n",
    "        #拼接\n",
    "        out4=self.bcat(out4)\n",
    "        out4=self.con4(out4)\n",
    "        out4=self.s4(out4)\n",
    "        out4=self.cond4(out4)\n",
    "        out4=self.sd4(out4)\n",
    "\n",
    "\n",
    "\n",
    "        out5=torch.cat((out4,out2),1)\n",
    "        out5=self.b5(out5)\n",
    "\n",
    "        out5=self.con5(out5)\n",
    "        out5=self.s5(out5)\n",
    "        out5=self.cond5(out5)\n",
    "        out5=self.sd5(out5)\n",
    "\n",
    "\n",
    "        out6=torch.cat((out5,out2),1)\n",
    "        out6=self.con6(out6)\n",
    "\n",
    "        return out6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 650 elements not 50",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b92f72c9a9c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m145\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m145\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\graph\\lib\\site-packages\\tensorwatch\\model_graph\\torchstat_utils.py\u001b[0m in \u001b[0;36mmodel_stats\u001b[1;34m(model, input_shape)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodel_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_stats2df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\graph\\lib\\site-packages\\tensorwatch\\model_graph\\torchstat_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, input_shape, clone_model)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mcollected_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollected_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\graph\\lib\\site-packages\\tensorwatch\\model_graph\\torchstat\\analyzer.py\u001b[0m in \u001b[0;36manalyze\u001b[1;34m(model, input_size, query_granularity)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mstat_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_leaf_modules_to_stat_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-2692317c33b3>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m#nl2=(nl2+nl3)*0.7+xx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mout4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_gcn2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mout4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[0mout4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcon4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mout4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\graph\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\graph\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1921\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1922\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1924\u001b[0m     )\n\u001b[0;32m   1925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: running_mean should contain 650 elements not 50"
     ]
    }
   ],
   "source": [
    "import tensorwatch as tw\n",
    "import torchvision.models\n",
    "\n",
    "tw.model_stats(model,[1, 200,145, 145])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch.utils.data as pydata\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from matplotlib import cm\n",
    "import spectral as spy\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from H_datapy import *\n",
    "\n",
    "#import CCnet2BModel1 as CC2B\n",
    "#import CCnetConcat2B1 as CCCon2B\n",
    "#from CCnetConcat2B1 import SSCDNonLModel_gcn\n",
    "import torch.nn.functional as F\n",
    "from autis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, ChebConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import Softmax\n",
    "class Self_Attn(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self,in_dim):\n",
    "        super(Self_Attn,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        #self.activation = activation\n",
    " \n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        #self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    " \n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B X C X W X H)\n",
    "            returns :\n",
    "                out : self attention value + input feature\n",
    "                attention: B X N X N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        m_batchsize,C,width ,height = x.size()\n",
    "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
    "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # BX (N) X (N)\n",
    "        #proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
    " \n",
    "        #out = torch.bmm(proj_value,attention.permute(0,2,1) )\n",
    "        #out = out.view(m_batchsize,C,width,height)\n",
    " \n",
    "        #out = self.gamma*out + x\n",
    "        #return out,attention\n",
    "        return attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSCDNonLModel_gcn(nn.Module):\n",
    "    def __init__(self, num_classes, n_bands, chanel):\n",
    "        super(SSCDNonLModel_gcn, self).__init__()\n",
    "        #self.num_Node=num_Node\n",
    "        self.bands=n_bands\n",
    "        chanel=chanel\n",
    "        kernel=5\n",
    "        CCChannel=25\n",
    "\n",
    "        self.b1=nn.BatchNorm2d(self.bands)\n",
    "        self.con1=nn.Conv2d(self.bands, chanel, 1, padding=0,bias=True)\n",
    "        self.s1=nn.Sigmoid()\n",
    "        self.cond1=nn.Conv2d(chanel, chanel, kernel, padding=2, groups=chanel, bias=True)\n",
    "        self.sd1=nn.Sigmoid()\n",
    "\n",
    "\n",
    "        self.b2=nn.BatchNorm2d(self.bands+chanel)\n",
    "        #self.nlcon1=NonLocalBlock(300, 300, True)\n",
    "        #self.gcn1=GCNtrans(300,1000)\n",
    "        #self.bcat=nn.BatchNorm2d(300+300)\n",
    "        self.con2=nn.Conv2d(self.bands+chanel, chanel, 1, padding=0,bias=True)\n",
    "        self.s2=nn.Sigmoid()\n",
    "        self.cond2=nn.Conv2d(chanel, CCChannel, kernel, padding=2, groups=25, bias=True)\n",
    "        self.sd2=nn.Sigmoid()\n",
    "\n",
    "        self.b4=nn.BatchNorm2d(CCChannel)\n",
    "\n",
    "        # GCN\n",
    "        #self.conv1 = GCNConv(dataset.num_features, 16, cached=True,normalize=not args.use_gdc)\n",
    "        self.att_map=Self_Attn(CCChannel)\n",
    "        self.conv1=GCNConv(1,int(CCChannel/2),cached=True)\n",
    "        self.conv2=GCNConv(int(CCChannel/2),CCChannel,cached=True)\n",
    "\n",
    "        # end\n",
    "        #self.b4=nn.BatchNorm2d(CCChannel)\n",
    "        #self.nlcon2=CrissCrossAttention(CCChannel)\n",
    "        #self.nlcon3=CrissCrossAttention(CCChannel)\n",
    "        self.bcat=nn.BatchNorm2d(CCChannel+CCChannel)\n",
    "        self.con4=nn.Conv2d(CCChannel+CCChannel, chanel, 1, padding=0, bias=True)\n",
    "        self.s4=nn.Sigmoid()\n",
    "        self.cond4=nn.Conv2d(chanel, chanel, kernel, padding=2, groups=chanel, bias=True)\n",
    "        self.sd4=nn.Sigmoid()\n",
    "\n",
    "        self.b5=nn.BatchNorm2d(CCChannel+chanel)\n",
    "        self.con5=nn.Conv2d(CCChannel+chanel, chanel, 1, padding=0, bias=True)\n",
    "        self.s5=nn.Sigmoid()\n",
    "        self.cond5=nn.Conv2d(chanel, chanel, kernel, padding=2, groups=chanel, bias=True)\n",
    "        self.sd5=nn.Sigmoid()\n",
    "\n",
    "        #self.b6=nn.BatchNorm2d(300+300)\n",
    "        self.con6=nn.Conv2d(chanel+CCChannel, num_classes+1, 1, padding=0, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = x.size(0)\n",
    "        H=x.size(2)\n",
    "        W=x.size(3)\n",
    "\n",
    "        out1=self.b1(x)\n",
    "        out1=self.con1(out1)\n",
    "        out1=self.s1(out1)\n",
    "        out1=self.cond1(out1)\n",
    "        out1=self.sd1(out1)\n",
    "\n",
    "        out2=torch.cat((out1,x),1)\n",
    "        out2=self.b2(out2)\n",
    "        out2=self.con2(out2)\n",
    "        out2=self.s2(out2)\n",
    "        out2=self.cond2(out2)\n",
    "        out2=self.sd2(out2)\n",
    "\n",
    "\n",
    "        xx=self.b4(out2)\n",
    "        att_map=self.att_map(xx)\n",
    "        adj=att_map\n",
    "        adj=adj.view(21025,21025)\n",
    "        adj[adj<0.5]=0\n",
    "        adj[adj>=0.5]=1\n",
    "        edge_index=adj.nonzero().t().contiguous()\n",
    "        \n",
    "        out_gcn1=self.conv1(xx.view(-1,1),edge_index)\n",
    "        #out_gcn1=self.conv1(out_finalconv.view(-1, 1),edge_index)\n",
    "        out_gcn1 = F.relu(out_gcn1)\n",
    "        out_gcn1 = F.dropout(out_gcn1, training=self.training)\n",
    "        out_gcn2=self.conv2(out_gcn1,edge_index)\n",
    "        #x=F.log_softmax(out_gcn2, dim=1)\n",
    "        #print(out_gcn2.shape)\n",
    "\n",
    "        out_gcn2=out_gcn2.view(1,-1,H,W)  \n",
    "\n",
    "\n",
    "        #nl2=(nl2+nl3)*0.7+xx\n",
    "        out4=torch.cat((xx, out_gcn2),1)\n",
    "        out4=self.bcat(out4)\n",
    "        out4=self.con4(out4)\n",
    "        out4=self.s4(out4)\n",
    "        out4=self.cond4(out4)\n",
    "        out4=self.sd4(out4)\n",
    "\n",
    "\n",
    "\n",
    "        out5=torch.cat((out4,out2),1)\n",
    "        out5=self.b5(out5)\n",
    "\n",
    "        out5=self.con5(out5)\n",
    "        out5=self.s5(out5)\n",
    "        out5=self.cond5(out5)\n",
    "        out5=self.sd5(out5)\n",
    "\n",
    "\n",
    "        out6=torch.cat((out5,out2),1)\n",
    "        out6=self.con6(out6)\n",
    "\n",
    "        return out6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from functions import CrissCrossAttention\n",
    "\n",
    "samples_type=['ratio','same_num'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG =1\n",
    "curr_train_ratio=0.1\n",
    "OA_ALL = []\n",
    "AA_ALL = []\n",
    "KPP_ALL = []\n",
    "AVG_ALL = []\n",
    "Seed_List=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if FLAG == 1:\n",
    "        data_mat = sio.loadmat('./Datasets/IndianPines/Indian_pines_corrected.mat')\n",
    "        data = data_mat['indian_pines_corrected']\n",
    "        gt_mat = sio.loadmat('./Datasets/IndianPines/Indian_pines_gt.mat')\n",
    "        gt = gt_mat['indian_pines_gt']\n",
    "        # 参数预设\n",
    "        train_ratio = 0.05  # 训练集比例。注意，训练集为按照‘每类’随机选取\n",
    "        val_ratio = 0.01 # 测试集比例.注意，验证集选取为从测试集整体随机选取，非按照每类\n",
    "        class_count = 16  # 样本类别数\n",
    "        learning_rate = 5e-4  # 学习率\n",
    "        weight_decay = 2e-5\n",
    "        max_epoch = 1800  # 迭代次数\n",
    "        split_height = 1\n",
    "        split_width = 1\n",
    "        dataset_name = \"indian\"  # 数据集名称\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_samples_per_class=curr_train_ratio#当定义为每类样本个数时,则该参数更改为训练样本数\n",
    "    val_samples=class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "    train_ratio=curr_train_ratio\n",
    "    if split_height == split_width == 1:\n",
    "            EDGE = 0\n",
    "    else:\n",
    "            EDGE = 5\n",
    "\n",
    "    cmap = cm.get_cmap('jet', class_count + 1)\n",
    "    plt.set_cmap(cmap)\n",
    "    m, n, d = data.shape  # 高光谱数据的三个维度\n",
    "    n_bands=d\n",
    "\n",
    "    data = np.reshape(data, [m * n, d])\n",
    "    minMax = preprocessing.StandardScaler()\n",
    "    data = minMax.fit_transform(data)\n",
    "    data = np.reshape(data, [m, n, d])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_seed in Seed_List:\n",
    "    # step2:随机10%数据作为训练样本。方式：给出训练数据与测试数据的GT\n",
    "    random.seed(curr_seed)\n",
    "    gt_reshape = np.reshape(gt, [-1])\n",
    "    train_rand_idx = []\n",
    "    val_rand_idx = []\n",
    "\n",
    "    if samples_type=='ratio':\n",
    "        #对每一类像素进行编号，取样\n",
    "        for i in range(class_count):\n",
    "            idx = np.where(gt_reshape == i + 1)[-1]\n",
    "            samplesCount = len(idx)\n",
    "            rand_list = [i for i in range(samplesCount)]  # 用于随机的列表\n",
    "            rand_idx = random.sample(rand_list, np.ceil(samplesCount * train_ratio).astype('int32'))  # 随机数数量 四舍五入(改为上取整)\n",
    "            #随机抽取进行train的像素索引\n",
    "            rand_real_idx_per_class = idx[rand_idx]\n",
    "            train_rand_idx.append(rand_real_idx_per_class)\n",
    "        # 总的用于训练的像素\n",
    "        train_rand_idx = np.array(train_rand_idx)\n",
    "        train_data_index = []\n",
    "        for c in range(train_rand_idx.shape[0]):\n",
    "            a = train_rand_idx[c]\n",
    "            for j in range(a.shape[0]):\n",
    "                train_data_index.append(a[j])\n",
    "        #最终用于训练的索引\n",
    "        train_data_index = np.array(train_data_index)\n",
    "\n",
    "        ##将测试集（所有样本，包括训练样本）也转化为特定形式\n",
    "        train_data_index = set(train_data_index)\n",
    "        all_data_index = [i for i in range(len(gt_reshape))]\n",
    "        all_data_index = set(all_data_index)\n",
    "\n",
    "        # 背景像元的标签\n",
    "        background_idx = np.where(gt_reshape == 0)[-1]\n",
    "        background_idx = set(background_idx)\n",
    "        test_data_index = all_data_index - train_data_index - background_idx\n",
    "\n",
    "        # 从测试集中随机选取部分样本作为验证集\n",
    "        val_data_count = int(val_ratio * (len(test_data_index) + len(train_data_index)))  # 验证集数量\n",
    "        val_data_index = random.sample(test_data_index, val_data_count)\n",
    "        val_data_index = set(val_data_index)\n",
    "        test_data_index = test_data_index - val_data_index  # 由于验证集为从测试集分裂出，所以测试集应减去验证集\n",
    "\n",
    "        # 将训练集 验证集 测试集 整理\n",
    "        test_data_index = list(test_data_index)\n",
    "        train_data_index = list(train_data_index)\n",
    "        val_data_index = list(val_data_index)\n",
    "\n",
    "                # 获取训练样本的标签图\n",
    "        train_samples_gt = np.zeros(gt_reshape.shape)\n",
    "        for i in range(len(train_data_index)):\n",
    "            # 除参与训练的像素外，其余gt设为0\n",
    "            train_samples_gt[train_data_index[i]] = gt_reshape[train_data_index[i]]\n",
    "            pass\n",
    "        Train_Label=np.reshape(train_samples_gt, [m,n])\n",
    "\n",
    "\n",
    "        # 获取测试样本的标签图\n",
    "        test_samples_gt = np.zeros(gt_reshape.shape)\n",
    "        for i in range(len(test_data_index)):\n",
    "            test_samples_gt[test_data_index[i]] = gt_reshape[test_data_index[i]]\n",
    "            pass\n",
    "\n",
    "        Test_Label = np.reshape(test_samples_gt, [m, n])  # 测试样本图\n",
    "\n",
    "        # 获取验证集样本的标签图\n",
    "        val_samples_gt = np.zeros(gt_reshape.shape)\n",
    "        for i in range(len(val_data_index)):\n",
    "            val_samples_gt[val_data_index[i]] = gt_reshape[val_data_index[i]]\n",
    "            pass\n",
    "        Val_Label=np.reshape(val_samples_gt,[m,n])\n",
    "\n",
    "        #############将train 和 test 和val 样本标签转化为向量形式###################\n",
    "        # 训练集\n",
    "        train_samples_gt = np.reshape(train_samples_gt, [m * n])\n",
    "        train_samples_gt_vector = np.zeros([m * n, class_count], np.float)\n",
    "        for i in range(train_samples_gt.shape[0]):\n",
    "            class_idx = train_samples_gt[i]\n",
    "            if class_idx != 0:\n",
    "                temp = np.zeros([class_count])\n",
    "                temp[int(class_idx - 1)] = 1\n",
    "                train_samples_gt_vector[i] = temp\n",
    "        train_samples_gt_vector = np.reshape(train_samples_gt_vector, [m, n, class_count])\n",
    "        # 测试集\n",
    "        test_samples_gt = np.reshape(test_samples_gt, [m * n])\n",
    "        test_samples_gt_vector = np.zeros([m * n, class_count], np.float)\n",
    "        for i in range(test_samples_gt.shape[0]):\n",
    "            class_idx = test_samples_gt[i]\n",
    "            if class_idx != 0:\n",
    "                temp = np.zeros([class_count])\n",
    "                temp[int(class_idx - 1)] = 1\n",
    "                test_samples_gt_vector[i] = temp\n",
    "        test_samples_gt_vector = np.reshape(test_samples_gt_vector, [m, n, class_count])\n",
    "        # 验证集\n",
    "        val_samples_gt = np.reshape(val_samples_gt, [m * n])\n",
    "        val_samples_gt_vector = np.zeros([m * n, class_count], np.float)\n",
    "        for i in range(val_samples_gt.shape[0]):\n",
    "            class_idx = val_samples_gt[i]\n",
    "            if class_idx != 0:\n",
    "                temp = np.zeros([class_count])\n",
    "                temp[int(class_idx - 1)] = 1\n",
    "                val_samples_gt_vector[i] = temp\n",
    "        val_samples_gt_vector = np.reshape(val_samples_gt_vector, [m, n, class_count])\n",
    "\n",
    "        ############制作训练数据和测试数据的gt掩膜.根据GT将带有标签的像元设置为全1向量##############\n",
    "        # 训练集\n",
    "        train_label_mask = np.zeros([m * n, class_count])\n",
    "        temp_ones = np.ones([class_count])\n",
    "        train_samples_gt = np.reshape(train_samples_gt, [m * n])\n",
    "        for i in range(m * n):\n",
    "            if train_samples_gt[i] != 0:\n",
    "                train_label_mask[i] = temp_ones\n",
    "        train_label_mask = np.reshape(train_label_mask, [m, n, class_count])\n",
    "\n",
    "        # 测试集\n",
    "        test_label_mask = np.zeros([m * n, class_count])\n",
    "        temp_ones = np.ones([class_count])\n",
    "        test_samples_gt = np.reshape(test_samples_gt, [m * n])\n",
    "        for i in range(m * n):\n",
    "            if test_samples_gt[i] != 0:\n",
    "                test_label_mask[i] = temp_ones\n",
    "        test_label_mask = np.reshape(test_label_mask, [m, n, class_count])\n",
    "\n",
    "        # 验证集\n",
    "        val_label_mask = np.zeros([m * n, class_count])\n",
    "        temp_ones = np.ones([class_count])\n",
    "        val_samples_gt = np.reshape(val_samples_gt, [m * n])\n",
    "        for i in range(m * n):\n",
    "            if val_samples_gt[i] != 0:\n",
    "                val_label_mask[i] = temp_ones\n",
    "        val_label_mask = np.reshape(val_label_mask, [m, n, class_count])\n",
    "\n",
    "        # 将数据扩展一维，以满足网络输入需求\n",
    "        # t1=Train_Label\n",
    "        # t1[Train_Label>0]=1\n",
    "        # num=t1.sum()\n",
    "        # t2=Test_Label\n",
    "        # t2[Test_Label>0]=1\n",
    "        # num2=t2.sum()\n",
    "        Train_Split_Data, Train_Split_GT = SpiltHSI(data, Train_Label, [split_height, split_width], EDGE)\n",
    "        Test_Split_Data, Test_Split_GT = SpiltHSI(data, Test_Label, [split_height, split_width], EDGE)\n",
    "        _, patch_height, patch_width, bands = Train_Split_Data.shape\n",
    "        patch_height -= EDGE * 2\n",
    "        patch_width -= EDGE * 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        zero_vector = np.zeros([class_count])\n",
    "        all_label_mask = np.ones([1, m, n, class_count])  # 设置一个全1的mask，使得网络输出所有分类标签\n",
    "\n",
    "    train_h=HData((np.transpose(Train_Split_Data,(0,3,1,2)).astype(\"float32\"), Train_Split_GT), None)\n",
    "    test_h=HData((np.transpose(Test_Split_Data,(0,3,1,2)).astype(\"float32\"), Test_Split_GT), None)\n",
    "    trainloader=torch.utils.data.DataLoader(train_h)\n",
    "    testloader=torch.utils.data.DataLoader(test_h)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SSCDNonLModel_gcn(class_count,n_bands,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SSCDNonLModel_gcn(\n  (b1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (con1): Conv2d(200, 150, kernel_size=(1, 1), stride=(1, 1))\n  (s1): Sigmoid()\n  (cond1): Conv2d(150, 150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=150)\n  (sd1): Sigmoid()\n  (b2): BatchNorm2d(350, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (con2): Conv2d(350, 150, kernel_size=(1, 1), stride=(1, 1))\n  (s2): Sigmoid()\n  (cond2): Conv2d(150, 25, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=25)\n  (sd2): Sigmoid()\n  (b4): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (att_map): Self_Attn(\n    (query_conv): Conv2d(25, 3, kernel_size=(1, 1), stride=(1, 1))\n    (key_conv): Conv2d(25, 3, kernel_size=(1, 1), stride=(1, 1))\n    (softmax): Softmax(dim=-1)\n  )\n  (conv1): GCNConv(1, 12)\n  (conv2): GCNConv(12, 25)\n  (bcat): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (con4): Conv2d(50, 150, kernel_size=(1, 1), stride=(1, 1))\n  (s4): Sigmoid()\n  (cond4): Conv2d(150, 150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=150)\n  (sd4): Sigmoid()\n  (b5): BatchNorm2d(175, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (con5): Conv2d(175, 150, kernel_size=(1, 1), stride=(1, 1))\n  (s5): Sigmoid()\n  (cond5): Conv2d(150, 150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=150)\n  (sd5): Sigmoid()\n  (con6): Conv2d(175, 17, kernel_size=(1, 1), stride=(1, 1))\n)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        att_map=self.att_map(xx)\n",
    "        adj=att_map\n",
    "        adj[adj<0.5]=0\n",
    "        adj[adj>=0.5]=1\n",
    "        edge_index=adj.nonzero().t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "att_map=torch.randn(1,21025,21025)\n",
    "adj=att_map\n",
    "adj[adj>=0.5]=1\n",
    "adj[adj<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([21025, 21025])\n"
     ]
    }
   ],
   "source": [
    "print(adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj=adj.view(21025,21025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index=adj.nonzero().t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 136395699])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}